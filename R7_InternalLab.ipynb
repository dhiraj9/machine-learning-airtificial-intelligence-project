{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFfDTfhlaEI_"
   },
   "source": [
    "# Transfer Learning MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNwbqCFRaEJC"
   },
   "source": [
    "* Train a simple convnet on the MNIST dataset the first 5 digits [0-4].\n",
    "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5-9]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Dnzaw1i5sXF"
   },
   "source": [
    "## MNIST Dataset\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. The MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpUULy1Z5sXF"
   },
   "source": [
    "Let's load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-uw1fGSV4nbR"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KiG7IPhm5sXG"
   },
   "outputs": [],
   "source": [
    "# Initialize the random number generator\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZqUiJM_Z5sXL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVw4wsuW5sXO"
   },
   "source": [
    "X_train and X_test contain greyscale RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgQ86Vhw5sXP"
   },
   "source": [
    "Let's visualize some numbers using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VZwg00gO5sXQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x152e47ca4f0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(\"Label: {}\".format(y_train[1000]))\n",
    "plt.imshow(X_train[1000], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p64mhwp95sXS"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxNAiWYd5sXT"
   },
   "source": [
    "### Create two datasets\n",
    "- First having digits from 0 to 4\n",
    "- Second having digits from 5 to 9\n",
    "\n",
    "Hint: use labels to separate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1807m1CL5sXT"
   },
   "outputs": [],
   "source": [
    "xt1=X_train[y_train<5]\n",
    "xte1=X_test[y_test<5]\n",
    "yt1=y_train[y_train<5]\n",
    "yte1=y_test[y_test<5]\n",
    "xt2=X_train[y_train>=5]\n",
    "xte2=X_test[y_test>=5]\n",
    "yt2=y_train[y_train>=5]\n",
    "yte2=y_test[y_test>=5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9jKcF1z5sXV"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMo7lvwQ5sXW"
   },
   "source": [
    "### Print shape of the data\n",
    "- print shape of all variables of both the datasets you created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kH7ZjEoH5sXW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30596, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5139, 28, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xte1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30596,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5139,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yte1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29404, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4861, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xte2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29404,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4861,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yte2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUU4PkKU5sXY"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I8ajqdt5sXY"
   },
   "source": [
    "### Reshape data\n",
    "- reshape first dataset\n",
    "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
    "- reshape features to pass it to a Conv2D layer\n",
    "- channel = 1\n",
    "- reshape features of first dataset only\n",
    "- do not reshape labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "38wgBEcz5sXa"
   },
   "outputs": [],
   "source": [
    "xt1=xt1.reshape(xt1.shape[0],28,28,1)\n",
    "xte1=xte1.reshape(xte1.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5H-BtNm5sXg"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ahCMtCl5sXh"
   },
   "source": [
    "### Normalize data\n",
    "- normalize first dataset\n",
    "- we must normalize our data as it is always required in neural network models\n",
    "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
    "- normalize X_train and X_test\n",
    "- make sure that the values are float so that we can get decimal points after division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "z4mti7pg5sXj"
   },
   "outputs": [],
   "source": [
    "xt1.astype('float32')\n",
    "xt1=xt1/255.0\n",
    "xte1.astype('float32')\n",
    "xte1=xte1/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfQ6545D5sXp"
   },
   "source": [
    "### Print shape of data and number of images\n",
    "- for first dataset\n",
    "- print shape of X_train\n",
    "- print number of images in X_train\n",
    "- print number of images in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "uQfQXZMo5sXp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30596, 28, 28, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30596"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5139"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xte1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oFjomSh5sXu"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lEFQQNk5sXu"
   },
   "source": [
    "### One-hot encode the class vector\n",
    "- encode labels of first dataset\n",
    "- convert class vectors (integers) to binary class matrix\n",
    "- convert y_train and y_test\n",
    "- number of classes: 5\n",
    "- we are doing this to use categorical_crossentropy as loss\n",
    "\n",
    "Hint: you can use tensorflow.keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "aejx3Zb35sXv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "yte1=to_categorical(yte1)\n",
    "yt1=to_categorical(yt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlkiipRA5sXw"
   },
   "source": [
    "## Question 6\n",
    "We will build our model by using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzYMC_xm5sXx"
   },
   "source": [
    "### Initialize a sequential model\n",
    "- define a sequential model\n",
    "- add 2 convolutional layers\n",
    "    - no of filters: 32\n",
    "    - kernel size: 3x3\n",
    "    - activation: \"relu\"\n",
    "    - input shape: (28, 28, 1) for first layer\n",
    "- add a max pooling layer of size 2x2\n",
    "- add a dropout layer\n",
    "    - dropout layers fight with the overfitting by disregarding some of the neurons while training\n",
    "    - use dropout rate 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "mDr-HKl-5sXx"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense\n",
    "m=Sequential([Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),Conv2D(32,(3,3),activation='relu'),MaxPooling2D(pool_size=(2,2)),Dropout(.2),Flatten(),Dense(128,activation='relu'),Dense(5,activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2RaPWiP5sXz"
   },
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ajGIM6t5sXz"
   },
   "source": [
    "### Add classification layers\n",
    "- do this after doing question 6\n",
    "- flatten the data\n",
    "    - add Flatten later\n",
    "    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n",
    "- add 2 dense layers\n",
    "    - number of neurons in first layer: 128\n",
    "    - number of neurons in last layer: number of classes\n",
    "    - activation function in first layer: relu\n",
    "    - activation function in last layer: softmax\n",
    "    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes\n",
    "- you can add a dropout layer in between, if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBxWAN265sX0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lhtm4d5K5sX1"
   },
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmXg8EaF5sX2"
   },
   "source": [
    "### Compile and fit the model\n",
    "- compile your model\n",
    "    - loss: \"categorical_crossentropy\"\n",
    "    - metrics: \"accuracy\"\n",
    "    - optimizer: \"sgd\"\n",
    "- fit your model\n",
    "    - give train data - features and labels\n",
    "    - batch size: 128\n",
    "    - epochs: 10\n",
    "    - give validation data - features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "cgclxC8s5sX4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 [==============================] - 28s 116ms/step - loss: 0.9548 - accuracy: 0.6863 - val_loss: 0.1225 - val_accuracy: 0.9638\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 29s 123ms/step - loss: 0.1459 - accuracy: 0.9550 - val_loss: 0.1063 - val_accuracy: 0.9687\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 30s 125ms/step - loss: 0.1222 - accuracy: 0.9625 - val_loss: 0.0781 - val_accuracy: 0.9776\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 29s 119ms/step - loss: 0.1117 - accuracy: 0.9652 - val_loss: 0.6103 - val_accuracy: 0.8212\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 29s 120ms/step - loss: 0.1118 - accuracy: 0.9666 - val_loss: 0.0691 - val_accuracy: 0.9784\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 27s 111ms/step - loss: 0.0952 - accuracy: 0.9696 - val_loss: 0.0543 - val_accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 27s 112ms/step - loss: 0.0826 - accuracy: 0.9741 - val_loss: 0.0487 - val_accuracy: 0.9856\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 27s 111ms/step - loss: 0.0794 - accuracy: 0.9751 - val_loss: 0.1164 - val_accuracy: 0.9619\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 28s 115ms/step - loss: 0.0738 - accuracy: 0.9769 - val_loss: 0.0498 - val_accuracy: 0.9858\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 27s 113ms/step - loss: 0.0716 - accuracy: 0.9782 - val_loss: 0.0392 - val_accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x152df25e760>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.compile(optimizer='sgd',metrics='accuracy',loss='categorical_crossentropy')\n",
    "m.fit(xt1,yt1,batch_size=128,epochs=10,validation_data=(xte1,yte1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSVZUu3p5sX5"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5TQ3yLV5sX6"
   },
   "source": [
    "### Evaluate model\n",
    "- evaluate your model and get accuracy\n",
    "- use test features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBvuD3ba5sX7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aUzOh9m5sX-"
   },
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srd-YYNH5sX-"
   },
   "source": [
    "## Transfer learning\n",
    "Now we will apply this model on second dataset (5-9 digits)\n",
    "\n",
    "- fix the first convolution layers so that the weights in the convolution layers dont get updated in the process of training\n",
    "- get the second dataset\n",
    "- train the last 2 dense layers\n",
    "- predict the accuracy and loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvhdH7D55sYA"
   },
   "source": [
    "### Make only dense layers trainable\n",
    "- set trainalble = False for all layers other than Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "brN7VZHFaEJ4"
   },
   "outputs": [],
   "source": [
    "m.layers[0].trainable=False\n",
    "m.layers[1].trainable=False\n",
    "m.layers[2].trainable=False\n",
    "m.layers[3].trainable=False\n",
    "m.layers[4].trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYR9VGzO5sYE"
   },
   "source": [
    "### Modify data\n",
    "- in your second data, class labels will start from 5 to 9 but for keras.utils.to_categorical the labels should start from 0\n",
    "- so you need to subtract 5 from train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lC5W75L35sYF"
   },
   "outputs": [],
   "source": [
    "yt2=yt2-5\n",
    "yte2=yte2-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGY3OTBt5sYG"
   },
   "source": [
    "### Reshape data\n",
    "- reshape second dataset\n",
    "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
    "- reshape features to pass it to a Conv2D layer\n",
    "- channel = 1\n",
    "- reshape features of first dataset only\n",
    "- do not reshape labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "0V7RUlRD5sYH"
   },
   "outputs": [],
   "source": [
    "xt2=xt2.reshape(xt2.shape[0],28,28,1)\n",
    "xte2=xte2.reshape(xte2.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7omqMQH5sYJ"
   },
   "source": [
    "### Normalize data\n",
    "- normalize second data\n",
    "- we must normalize our data as it is always required in neural network models\n",
    "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
    "- normalize X_train and X_test\n",
    "- make sure that the values are float so that we can get decimal points after division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "PEFYNHRp5sYJ"
   },
   "outputs": [],
   "source": [
    "xt2=xt2.astype('float32')\n",
    "xte2=xte2.astype('float32')\n",
    "xt2/=255.0\n",
    "xte2/=255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OfdlF655sYM"
   },
   "source": [
    "### Print shape of data and number of images\n",
    "- print shape of X_train\n",
    "- print number of images in X_train\n",
    "- print number of images in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "bZEkCQ-P5sYO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29404, 28, 28, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29404"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4861"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xte2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_3-0Qwo5sYQ"
   },
   "source": [
    "### One-hot encode the class vector\n",
    "- convert class vectors (integers) to binary class matrix\n",
    "- convert y_train and y_test\n",
    "- number of classes: 5\n",
    "- we are doing this to use categorical_crossentropy as loss\n",
    "\n",
    "Hint: you can use tensorflow.keras.utils.to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "k46Me5Re5sYR"
   },
   "outputs": [],
   "source": [
    "yt2=to_categorical(yt2)\n",
    "yte2=to_categorical(yte2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9xEoW515sYS"
   },
   "source": [
    "### Fit the model\n",
    "- give train data - features and labels\n",
    "- batch size: 128\n",
    "- epochs: 10\n",
    "- give validation data - features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "B6f-XAc-5sYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "230/230 [==============================] - 27s 118ms/step - loss: 0.3740 - accuracy: 0.8790 - val_loss: 0.1889 - val_accuracy: 0.9329\n",
      "Epoch 2/10\n",
      "230/230 [==============================] - 26s 113ms/step - loss: 0.1773 - accuracy: 0.9439 - val_loss: 0.1562 - val_accuracy: 0.9484\n",
      "Epoch 3/10\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.1415 - accuracy: 0.9547 - val_loss: 0.1097 - val_accuracy: 0.9667\n",
      "Epoch 4/10\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.1217 - accuracy: 0.9610 - val_loss: 0.0960 - val_accuracy: 0.9691\n",
      "Epoch 5/10\n",
      "230/230 [==============================] - 27s 116ms/step - loss: 0.1099 - accuracy: 0.9652 - val_loss: 0.0920 - val_accuracy: 0.9698\n",
      "Epoch 6/10\n",
      "230/230 [==============================] - 26s 114ms/step - loss: 0.1020 - accuracy: 0.9665 - val_loss: 0.0978 - val_accuracy: 0.9650\n",
      "Epoch 7/10\n",
      "230/230 [==============================] - 25s 110ms/step - loss: 0.0932 - accuracy: 0.9705 - val_loss: 0.0805 - val_accuracy: 0.9749\n",
      "Epoch 8/10\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.0880 - accuracy: 0.9714 - val_loss: 0.0793 - val_accuracy: 0.9735\n",
      "Epoch 9/10\n",
      "230/230 [==============================] - 25s 109ms/step - loss: 0.0849 - accuracy: 0.9719 - val_loss: 0.0736 - val_accuracy: 0.9763\n",
      "Epoch 10/10\n",
      "230/230 [==============================] - 26s 112ms/step - loss: 0.0810 - accuracy: 0.9740 - val_loss: 0.0721 - val_accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15285d833a0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(xt2,yt2,batch_size=128,epochs=10,validation_data=(xte2,yte2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85ginrII5sYV"
   },
   "source": [
    "### Evaluate model\n",
    "- evaluate your model and get accuracy\n",
    "- use test features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k11-vrsm5sYW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTNhSDqn5sYY"
   },
   "source": [
    "-----------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Questions - CNN-Transfer Learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
